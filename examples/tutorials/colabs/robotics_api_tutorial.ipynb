{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[setup]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Installation { display-mode: \"form\" }\n",
    "# @markdown (double click to show code).\n",
    "\n",
    "!curl -L https://raw.githubusercontent.com/facebookresearch/habitat-sim/master/examples/colab_utils/colab_install.sh | PACKAGE=habitat-sim-ao bash -s\n",
    "!wget -c http://dl.fbaipublicfiles.com/habitat/mp3d_example.zip && unzip -o mp3d_example.zip -d /content/habitat-sim/data/scene_datasets/mp3d/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import magnum as mn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import habitat_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import habitat_sim.utils.common as ut\n",
    "import habitat_sim.utils.viz_utils as vut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "data_path = os.path.join(dir_path, \"../../data\")\n",
    "output_path = os.path.join(dir_path, \"URDF_robotics_tutorial_output/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_process_memory_usage():\n",
    "    import os\n",
    "\n",
    "    import psutil\n",
    "\n",
    "    return psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all_objects(sim):\n",
    "    for ob_id in sim.get_existing_object_ids():\n",
    "        sim.remove_object(ob_id)\n",
    "    for ob_id in sim.get_existing_articulated_object_ids():\n",
    "        sim.remove_articulated_object(ob_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_agent(sim):\n",
    "    # place our agent in the scene\n",
    "    agent_state = habitat_sim.AgentState()\n",
    "    agent_state.position = [-0.15, -0.1, 1.0]\n",
    "    # agent_state.position = [-0.15, -1.6, 1.0]\n",
    "    agent_state.rotation = np.quaternion(-0.83147, 0, 0.55557, 0)\n",
    "    agent = sim.initialize_agent(0, agent_state)\n",
    "    return agent.scene_node.transformation_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_configuration():\n",
    "    # simulator configuration\n",
    "    backend_cfg = habitat_sim.SimulatorConfiguration()\n",
    "    backend_cfg.scene_id = \"data/scene_datasets/habitat-test-scenes/apartment_1.glb\"\n",
    "    backend_cfg.enable_physics = True\n",
    "\n",
    "    # sensor configurations\n",
    "    # Note: all sensors must have the same resolution\n",
    "    # setup 2 rgb sensors for 1st and 3rd person views\n",
    "    camera_resolution = [540, 720]\n",
    "    sensors = {\n",
    "        \"rgba_camera_1stperson\": {\n",
    "            \"sensor_type\": habitat_sim.SensorType.COLOR,\n",
    "            \"resolution\": camera_resolution,\n",
    "            \"position\": [0.0, 0.0, 0.0],\n",
    "            \"orientation\": [0.0, 0.0, 0.0],\n",
    "        },\n",
    "        \"depth_camera_1stperson\": {\n",
    "            \"sensor_type\": habitat_sim.SensorType.DEPTH,\n",
    "            \"resolution\": camera_resolution,\n",
    "            \"position\": [0.0, 0.0, 0.0],\n",
    "            \"orientation\": [0.0, 0.0, 0.0],\n",
    "        },\n",
    "    }\n",
    "\n",
    "    sensor_specs = []\n",
    "    for sensor_uuid, sensor_params in sensors.items():\n",
    "        sensor_spec = habitat_sim.CameraSensorSpec()\n",
    "        sensor_spec.uuid = sensor_uuid\n",
    "        sensor_spec.sensor_type = sensor_params[\"sensor_type\"]\n",
    "        sensor_spec.resolution = sensor_params[\"resolution\"]\n",
    "        sensor_spec.position = sensor_params[\"position\"]\n",
    "        sensor_spec.orientation = sensor_params[\"orientation\"]\n",
    "        sensor_specs.append(sensor_spec)\n",
    "\n",
    "    # agent configuration\n",
    "    agent_cfg = habitat_sim.agent.AgentConfiguration()\n",
    "    agent_cfg.sensor_specifications = sensor_specs\n",
    "\n",
    "    return habitat_sim.Configuration(backend_cfg, [agent_cfg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(sim, dt=1.0, get_frames=True):\n",
    "    # simulate dt seconds at 60Hz to the nearest fixed timestep\n",
    "    print(\"Simulating \" + str(dt) + \" world seconds.\")\n",
    "    observations = []\n",
    "    start_time = sim.get_world_time()\n",
    "    while sim.get_world_time() < start_time + dt:\n",
    "        sim.step_physics(1.0 / 60.0)\n",
    "        if get_frames:\n",
    "            observations.append(sim.get_sensor_observations())\n",
    "\n",
    "    return observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_robot_from_agent(\n",
    "    sim,\n",
    "    robot_id,\n",
    "    angle_correction=-1.56,\n",
    "    local_base_pos=None,\n",
    "):\n",
    "    if local_base_pos is None:\n",
    "        local_base_pos = np.array([0.0, -0.1, -2.0])\n",
    "    # place the robot root state relative to the agent\n",
    "    agent_transform = sim.agents[0].scene_node.transformation_matrix()\n",
    "    base_transform = mn.Matrix4.rotation(\n",
    "        mn.Rad(angle_correction), mn.Vector3(1.0, 0, 0)\n",
    "    )\n",
    "    base_transform.translation = agent_transform.transform_point(local_base_pos)\n",
    "    sim.set_articulated_object_root_state(robot_id, base_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urdf_files = {\n",
    "    \"aliengo\": os.path.join(data_path, \"URDF_demo_assets/aliengo/urdf/aliengo.urdf\"),\n",
    "    \"iiwa\": os.path.join(data_path, \"test_assets/urdf/kuka_iiwa/model_free_base.urdf\"),\n",
    "    \"locobot\": os.path.join(data_path, \"URDF_demo_assets/aliengo/urdf/aliengo.urdf\"),\n",
    "    \"locobot_light\": os.path.join(\n",
    "        data_path, \"URDF_demo_assets/aliengo/urdf/aliengo.urdf\"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_urdf_memory():\n",
    "    # test for memory leaks related to adding/removing AO's from URDF\n",
    "    # process_memory_tracking = [get_process_memory_usage()]\n",
    "    process_memory_tracking = []\n",
    "\n",
    "    # create the simulator\n",
    "    cfg = make_configuration()\n",
    "    sim = habitat_sim.Simulator(cfg)\n",
    "\n",
    "    # process_memory_tracking.append(get_process_memory_usage())\n",
    "\n",
    "    # load a URDF file\n",
    "    robot_key = \"fetch\"\n",
    "    robot_file = urdf_files[robot_key]\n",
    "    for _sample in range(1000):\n",
    "\n",
    "        robot_id = sim.add_articulated_object_from_urdf(robot_file)\n",
    "        process_memory_tracking.append(get_process_memory_usage())\n",
    "        sim.remove_articulated_object(robot_id)\n",
    "        process_memory_tracking.append(get_process_memory_usage())\n",
    "\n",
    "    # graph the results\n",
    "    plt.plot(process_memory_tracking)\n",
    "    plt.title(\"Memory (MB) at add/remove URDF. (\" + str(robot_key) + \")\")\n",
    "    plt.xlabel(\"Query #\")\n",
    "    plt.ylabel(\"Process Memory (MB)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_contact_profile():\n",
    "    cfg = make_configuration()\n",
    "    with habitat_sim.Simulator(cfg) as sim:\n",
    "        place_agent(sim)\n",
    "        observations = []\n",
    "\n",
    "        # add a robot to the scene\n",
    "        robot_file = urdf_files[\"aliengo\"]\n",
    "        robot_id = sim.add_articulated_object_from_urdf(robot_file)\n",
    "\n",
    "        # gets nothing because physics has not stepped yet\n",
    "        print(sim.get_physics_step_collision_summary())\n",
    "\n",
    "        # gets nothing because no active collisions yet\n",
    "        sim.step_physics(0.1)\n",
    "        print(sim.get_physics_step_collision_summary())\n",
    "\n",
    "        # give time for the robot to hit the ground then check contacts\n",
    "        sim.step_physics(1.0)\n",
    "        print(\"Step Collision Summary:\")\n",
    "        print(sim.get_physics_step_collision_summary())\n",
    "\n",
    "        # now add two colliding robots and run discrete collision detection\n",
    "        sim.remove_articulated_object(robot_id)\n",
    "        robot_id1 = sim.add_articulated_object_from_urdf(robot_file)\n",
    "        robot_id2 = sim.add_articulated_object_from_urdf(robot_file)\n",
    "        place_robot_from_agent(sim, robot_id1)\n",
    "        place_robot_from_agent(\n",
    "            sim, robot_id2, local_base_pos=np.array([0.15, -0.1, -2.0])\n",
    "        )\n",
    "        sim.perform_discrete_collision_detection()\n",
    "        print(\"Step Collision Summary:\")\n",
    "        print(sim.get_physics_step_collision_summary())\n",
    "        print(\n",
    "            \"Num overlapping pairs: \"\n",
    "            + str(sim.get_physics_num_active_overlapping_pairs())\n",
    "        )\n",
    "        print(\n",
    "            \"Num active contact points: \"\n",
    "            + str(sim.get_physics_num_active_contact_points())\n",
    "        )\n",
    "        contact_points = sim.get_physics_contact_points()\n",
    "        print(\"Active contact points: \")\n",
    "        for cp_ix, cp in enumerate(contact_points):\n",
    "            print(\" Contact Point \" + str(cp_ix) + \":\")\n",
    "            print(\"     object_id_a = \" + str(cp.object_id_a))\n",
    "            print(\"     object_id_b = \" + str(cp.object_id_b))\n",
    "            print(\"     link_id_a = \" + str(cp.link_id_a))\n",
    "            print(\"     link_id_b = \" + str(cp.link_id_b))\n",
    "            print(\"     position_on_a_in_ws = \" + str(cp.position_on_a_in_ws))\n",
    "            print(\"     position_on_b_in_ws = \" + str(cp.position_on_b_in_ws))\n",
    "            print(\n",
    "                \"     contact_normal_on_b_in_ws = \" + str(cp.contact_normal_on_b_in_ws)\n",
    "            )\n",
    "            print(\"     contact_distance = \" + str(cp.contact_distance))\n",
    "            print(\"     normal_force = \" + str(cp.normal_force))\n",
    "            print(\"     linear_friction_force1 = \" + str(cp.linear_friction_force1))\n",
    "            print(\"     linear_friction_force2 = \" + str(cp.linear_friction_force2))\n",
    "            print(\n",
    "                \"     linear_friction_direction1 = \"\n",
    "                + str(cp.linear_friction_direction1)\n",
    "            )\n",
    "            print(\n",
    "                \"     linear_friction_direction2 = \"\n",
    "                + str(cp.linear_friction_direction2)\n",
    "            )\n",
    "            print(\"     is_active = \" + str(cp.is_active))\n",
    "\n",
    "        observations.append(sim.get_sensor_observations())\n",
    "        # TODO: visualize the contact points\n",
    "        im = vut.observation_to_image(\n",
    "            observations[-1][\"rgba_camera_1stperson\"], \"color\"\n",
    "        )\n",
    "        im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_constraints(make_video=True, show_video=True):\n",
    "    # [initialize]\n",
    "    # create the simulator\n",
    "    cfg = make_configuration()\n",
    "    with habitat_sim.Simulator(cfg) as sim:\n",
    "        place_agent(sim)\n",
    "        observations = []\n",
    "\n",
    "        # load a URDF file\n",
    "        robot_file = urdf_files[\"aliengo\"]\n",
    "        robot_id = sim.add_articulated_object_from_urdf(robot_file)\n",
    "        ef_link_id = 16  # foot = 16, TODO: base = -1\n",
    "        ef_link2_id = 12\n",
    "        iiwa_ef_link = 6\n",
    "\n",
    "        # add a constraint vis object\n",
    "        obj_mgr = sim.get_object_template_manager()\n",
    "        sphere_id = sim.add_object_by_handle(obj_mgr.get_template_handles(\"sphere\")[0])\n",
    "        sim.set_object_motion_type(habitat_sim.physics.MotionType.KINEMATIC, sphere_id)\n",
    "        sim.set_object_is_collidable(False, sphere_id)\n",
    "\n",
    "        for test_case in range(6):\n",
    "            sim.reset_articulated_object(robot_id)\n",
    "            place_robot_from_agent(sim, robot_id)\n",
    "\n",
    "            # Test constraint types:\n",
    "            if test_case == 0:\n",
    "                # - AO -> world\n",
    "                # should constrain to the center of the sphere\n",
    "                link_rigid_state = sim.get_articulated_link_rigid_state(\n",
    "                    robot_id, ef_link_id\n",
    "                )\n",
    "                sim.set_translation(link_rigid_state.translation, sphere_id)\n",
    "                constraint_id = sim.create_articulated_p2p_constraint(\n",
    "                    object_id=robot_id,\n",
    "                    link_id=ef_link_id,\n",
    "                    global_constraint_point=link_rigid_state.translation,\n",
    "                )\n",
    "                observations += simulate(sim, dt=3.0, get_frames=make_video)\n",
    "                sim.remove_constraint(constraint_id)\n",
    "            elif test_case == 1:\n",
    "                # - AO -> world w/ offset\n",
    "                # should constrain to the boundary of the sphere\n",
    "                link_rigid_state = sim.get_articulated_link_rigid_state(\n",
    "                    robot_id, ef_link_id\n",
    "                )\n",
    "                link_offset = mn.Vector3(0, 0, -0.1)\n",
    "                global_constraint_position = link_rigid_state.translation\n",
    "                sim.set_translation(global_constraint_position, sphere_id)\n",
    "                constraint_id = sim.create_articulated_p2p_constraint(\n",
    "                    object_id=robot_id,\n",
    "                    link_id=ef_link_id,\n",
    "                    link_offset=link_offset,\n",
    "                    global_constraint_point=global_constraint_position,\n",
    "                )\n",
    "                observations += simulate(sim, dt=3.0, get_frames=make_video)\n",
    "                sim.remove_constraint(constraint_id)\n",
    "            elif test_case == 2:\n",
    "                # - AO -> AO (w/ offsets)\n",
    "                robot_id2 = sim.add_articulated_object_from_urdf(robot_file)\n",
    "                place_robot_from_agent(\n",
    "                    sim=sim,\n",
    "                    robot_id=robot_id2,\n",
    "                    local_base_pos=np.array([0.35, -0.1, -2.0]),\n",
    "                )\n",
    "                # attach the agents' feet together\n",
    "                link_b_rigid_state = sim.get_articulated_link_rigid_state(\n",
    "                    robot_id2, ef_link_id\n",
    "                )\n",
    "                constraint_id = sim.create_articulated_p2p_constraint(\n",
    "                    object_id_a=robot_id,\n",
    "                    link_id_a=ef_link_id,\n",
    "                    offset_a=mn.Vector3(),\n",
    "                    object_id_b=robot_id2,\n",
    "                    link_id_b=ef_link_id,\n",
    "                    offset_b=mn.Vector3(),\n",
    "                )\n",
    "\n",
    "                # constrain 1st robot in the air by other foot\n",
    "                link_a2_rigid_state = sim.get_articulated_link_rigid_state(\n",
    "                    robot_id, ef_link2_id\n",
    "                )\n",
    "                global_constraint_position = (\n",
    "                    link_a2_rigid_state.translation + mn.Vector3(0, 1.5, 0)\n",
    "                )\n",
    "                sim.set_translation(global_constraint_position, sphere_id)\n",
    "                # note: increase max impulse: the combined weight of the robots is greater than the default impulse correction (2)\n",
    "                constraint_id2 = sim.create_articulated_p2p_constraint(\n",
    "                    object_id=robot_id,\n",
    "                    link_id=ef_link2_id,\n",
    "                    link_offset=mn.Vector3(),\n",
    "                    global_constraint_point=global_constraint_position,\n",
    "                    max_impulse=6,\n",
    "                )\n",
    "\n",
    "                observations += simulate(sim, dt=3.0, get_frames=make_video)\n",
    "                sim.remove_constraint(constraint_id)\n",
    "                sim.remove_constraint(constraint_id2)\n",
    "                sim.remove_articulated_object(robot_id2)\n",
    "            elif test_case == 3:\n",
    "                # - AO -> AO (global)\n",
    "                robot_id2 = sim.add_articulated_object_from_urdf(\n",
    "                    urdf_files[\"iiwa\"], True\n",
    "                )\n",
    "                place_robot_from_agent(\n",
    "                    sim=sim,\n",
    "                    robot_id=robot_id2,\n",
    "                    local_base_pos=np.array([0.35, -0.4, -2.0]),\n",
    "                )\n",
    "                jm_settings = habitat_sim.physics.JointMotorSettings()\n",
    "                jm_settings.position_gain = 2.0\n",
    "                sim.create_motors_for_all_dofs(robot_id2, jm_settings)\n",
    "                # TODO: not a great test, could be a better setup\n",
    "                # attach two agent feet to the iiwa end effector\n",
    "                link_b_rigid_state = sim.get_articulated_link_rigid_state(\n",
    "                    robot_id2, iiwa_ef_link\n",
    "                )\n",
    "                global_constraint_position = link_b_rigid_state.translation\n",
    "                sim.set_translation(global_constraint_position, sphere_id)\n",
    "                constraint_id = sim.create_articulated_p2p_constraint(\n",
    "                    object_id_a=robot_id,\n",
    "                    link_id_a=ef_link_id,\n",
    "                    object_id_b=robot_id2,\n",
    "                    link_id_b=iiwa_ef_link,\n",
    "                    global_constraint_point=global_constraint_position,\n",
    "                    max_impulse=4,\n",
    "                )\n",
    "                constraint_id2 = sim.create_articulated_p2p_constraint(\n",
    "                    object_id_a=robot_id,\n",
    "                    link_id_a=ef_link2_id,\n",
    "                    object_id_b=robot_id2,\n",
    "                    link_id_b=iiwa_ef_link,\n",
    "                    global_constraint_point=global_constraint_position,\n",
    "                    max_impulse=4,\n",
    "                )\n",
    "\n",
    "                observations += simulate(sim, dt=3.0, get_frames=make_video)\n",
    "                sim.remove_constraint(constraint_id)\n",
    "                sim.remove_constraint(constraint_id2)\n",
    "                sim.remove_articulated_object(robot_id2)\n",
    "            elif test_case == 4:\n",
    "                # - AO -> rigid\n",
    "\n",
    "                # tilt the camera down\n",
    "                prev_state = sim.get_agent(0).scene_node.rotation\n",
    "                sim.get_agent(0).scene_node.rotation = (\n",
    "                    mn.Quaternion.rotation(\n",
    "                        mn.Rad(-0.4), prev_state.transform_vector(mn.Vector3(1.0, 0, 0))\n",
    "                    )\n",
    "                    * prev_state\n",
    "                )\n",
    "\n",
    "                # attach an active sphere to one robot foot w/ pivot at the object center\n",
    "                active_sphere_id = sim.add_object_by_handle(\n",
    "                    obj_mgr.get_template_handles(\"sphere\")[0]\n",
    "                )\n",
    "                link_rigid_state = sim.get_articulated_link_rigid_state(\n",
    "                    robot_id, ef_link_id\n",
    "                )\n",
    "                link2_rigid_state = sim.get_articulated_link_rigid_state(\n",
    "                    robot_id, ef_link2_id\n",
    "                )\n",
    "                sim.set_translation(\n",
    "                    link2_rigid_state.translation + mn.Vector3(0, -0.1, 0),\n",
    "                    active_sphere_id,\n",
    "                )\n",
    "                constraint_id = sim.create_articulated_p2p_constraint(\n",
    "                    object_id_a=robot_id,\n",
    "                    link_id=ef_link2_id,\n",
    "                    object_id_b=active_sphere_id,\n",
    "                    max_impulse=4,\n",
    "                )\n",
    "                # attach the visual sphere to another robot foot w/ pivots\n",
    "                sim.set_object_motion_type(\n",
    "                    habitat_sim.physics.MotionType.DYNAMIC, sphere_id\n",
    "                )\n",
    "                constraint_id2 = sim.create_articulated_p2p_constraint(\n",
    "                    object_id_a=robot_id,\n",
    "                    link_id=ef_link_id,\n",
    "                    object_id_b=sphere_id,\n",
    "                    pivot_a=mn.Vector3(0.1, 0, 0),\n",
    "                    pivot_b=mn.Vector3(-0.1, 0, 0),\n",
    "                    max_impulse=4,\n",
    "                )\n",
    "\n",
    "                observations += simulate(sim, dt=3.0, get_frames=make_video)\n",
    "                sim.remove_constraint(constraint_id)\n",
    "                sim.remove_constraint(constraint_id2)\n",
    "                sim.set_object_motion_type(\n",
    "                    habitat_sim.physics.MotionType.KINEMATIC, sphere_id\n",
    "                )\n",
    "                sim.remove_object(active_sphere_id)\n",
    "\n",
    "                sim.get_agent(0).scene_node.rotation = prev_state\n",
    "            elif test_case == 5:\n",
    "                # - AO -> rigid (fixed) TODO: not working as expected\n",
    "\n",
    "                # tilt the camera down\n",
    "                prev_state = sim.get_agent(0).scene_node.rotation\n",
    "                sim.get_agent(0).scene_node.rotation = (\n",
    "                    mn.Quaternion.rotation(\n",
    "                        mn.Rad(-0.4), prev_state.transform_vector(mn.Vector3(1.0, 0, 0))\n",
    "                    )\n",
    "                    * prev_state\n",
    "                )\n",
    "\n",
    "                # attach an active sphere to one robot foot w/ pivot at the object center\n",
    "                active_sphere_id = sim.add_object_by_handle(\n",
    "                    obj_mgr.get_template_handles(\"sphere\")[0]\n",
    "                )\n",
    "                link2_rigid_state = sim.get_articulated_link_rigid_state(\n",
    "                    robot_id, ef_link2_id\n",
    "                )\n",
    "                sim.set_translation(\n",
    "                    link2_rigid_state.translation + mn.Vector3(0, -0.15, 0),\n",
    "                    active_sphere_id,\n",
    "                )\n",
    "                constraint_id = sim.create_articulated_fixed_constraint(\n",
    "                    object_id_a=robot_id,\n",
    "                    link_id=ef_link2_id,\n",
    "                    object_id_b=active_sphere_id,\n",
    "                    max_impulse=4,\n",
    "                )\n",
    "\n",
    "                observations += simulate(sim, dt=3.0, get_frames=make_video)\n",
    "                sim.remove_constraint(constraint_id)\n",
    "                sim.remove_object(active_sphere_id)\n",
    "\n",
    "                sim.get_agent(0).scene_node.rotation = prev_state\n",
    "\n",
    "        if make_video:\n",
    "            vut.make_video(\n",
    "                observations,\n",
    "                \"rgba_camera_1stperson\",\n",
    "                \"color\",\n",
    "                output_path + \"test_constraints\",\n",
    "                open_vid=show_video,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is wrapped such that it can be added to a unit test\n",
    "def main(make_video=True, show_video=True):\n",
    "\n",
    "    # [initialize]\n",
    "    # create the simulator\n",
    "    cfg = make_configuration()\n",
    "    with habitat_sim.Simulator(cfg) as sim:\n",
    "        place_agent(sim)\n",
    "        observations = []\n",
    "\n",
    "        # load a URDF file\n",
    "        robot_file = urdf_files[\"iiwa\"]\n",
    "        robot_id = sim.add_articulated_object_from_urdf(robot_file)\n",
    "\n",
    "        # place the robot root state relative to the agent\n",
    "        place_robot_from_agent(sim, robot_id)\n",
    "\n",
    "        # simulate\n",
    "        observations += simulate(sim, dt=1.5, get_frames=make_video)\n",
    "\n",
    "        for iteration in range(1, 4):\n",
    "            # remove the object\n",
    "            sim.remove_articulated_object(robot_id)\n",
    "\n",
    "            # load a URDF file\n",
    "            robot_file = urdf_files[\"aliengo\"]\n",
    "            urdf_global_scale = iteration / 2.0\n",
    "            robot_id = sim.add_articulated_object_from_urdf(\n",
    "                robot_file, False, urdf_global_scale\n",
    "            )\n",
    "            print(\"Scaled URDF by \" + str(urdf_global_scale))\n",
    "\n",
    "            # place the robot root state relative to the agent\n",
    "            place_robot_from_agent(sim, robot_id)\n",
    "\n",
    "            # set a better initial joint state for the aliengo\n",
    "            if robot_file == urdf_files[\"aliengo\"]:\n",
    "                pose = sim.get_articulated_object_positions(robot_id)\n",
    "                calfDofs = [2, 5, 8, 11]\n",
    "                for dof in calfDofs:\n",
    "                    pose[dof] = -1.0\n",
    "                    pose[dof - 1] = 0.45\n",
    "                    # also set a thigh\n",
    "                sim.set_articulated_object_positions(robot_id, pose)\n",
    "\n",
    "            # simulate\n",
    "            observations += simulate(sim, dt=1.5, get_frames=make_video)\n",
    "\n",
    "        # get/set forces and velocities\n",
    "        tau = sim.get_articulated_object_forces(robot_id)\n",
    "        sim.set_articulated_object_forces(robot_id, tau)\n",
    "\n",
    "        vel = sim.get_articulated_object_velocities(robot_id)\n",
    "        sim.set_articulated_object_velocities(robot_id, vel)\n",
    "\n",
    "        # reset the object state (sets dof positions/velocities/forces to 0, recomputes forward kinematics, udpate collision state)\n",
    "        sim.reset_articulated_object(robot_id)\n",
    "        # note: reset does not change the robot base state, do this manually\n",
    "        place_robot_from_agent(sim, robot_id)\n",
    "\n",
    "        # set sleeping ON\n",
    "        sim.set_articulated_object_sleep(robot_id, True)\n",
    "        assert sim.get_articulated_object_sleep(robot_id) is True\n",
    "\n",
    "        observations += simulate(sim, dt=1.0, get_frames=make_video)\n",
    "\n",
    "        # set sleeping OFF\n",
    "        sim.set_articulated_object_sleep(robot_id, False)\n",
    "        assert sim.get_articulated_object_sleep(robot_id) is False\n",
    "\n",
    "        observations += simulate(sim, dt=1.5, get_frames=make_video)\n",
    "\n",
    "        # get/set motiontype (KINEMATIC vs. DYNAMIC)\n",
    "        sim.set_articulated_object_motion_type(\n",
    "            robot_id, habitat_sim.physics.MotionType.KINEMATIC\n",
    "        )\n",
    "        assert (\n",
    "            sim.get_articulated_object_motion_type(robot_id)\n",
    "            == habitat_sim.physics.MotionType.KINEMATIC\n",
    "        )\n",
    "\n",
    "        # reset the object state (sets dof positions/velocities/forces to 0, recomputes forward kinematics, udpate collision state)\n",
    "        sim.reset_articulated_object(robot_id)\n",
    "        # note: reset does not change the robot base state, do this manually\n",
    "        place_robot_from_agent(sim, robot_id)\n",
    "\n",
    "        # get rigid state of robot links and show proxy object at each link COM\n",
    "        obj_mgr = sim.get_object_template_manager()\n",
    "        cube_id = sim.add_object_by_handle(obj_mgr.get_template_handles(\"cube\")[0])\n",
    "        sim.set_object_motion_type(habitat_sim.physics.MotionType.KINEMATIC, cube_id)\n",
    "        sim.set_object_is_collidable(False, cube_id)\n",
    "        num_links = sim.get_num_articulated_links(robot_id)\n",
    "        for link_id in range(num_links):\n",
    "            link_rigid_state = sim.get_articulated_link_rigid_state(robot_id, link_id)\n",
    "            sim.set_translation(link_rigid_state.translation, cube_id)\n",
    "            sim.set_rotation(link_rigid_state.rotation, cube_id)\n",
    "            # get the link friction\n",
    "            print(\n",
    "                \"Link \"\n",
    "                + str(link_id)\n",
    "                + \" friction coefficient = \"\n",
    "                + str(sim.get_articulated_link_friction(robot_id, link_id))\n",
    "            )\n",
    "            # Note: set this with 'sim.get_articulated_link_friction(robot_id, link_id, friction)'\n",
    "            observations += simulate(sim, dt=0.5, get_frames=make_video)\n",
    "        sim.remove_object(cube_id)\n",
    "\n",
    "        sim.set_articulated_object_motion_type(\n",
    "            robot_id, habitat_sim.physics.MotionType.DYNAMIC\n",
    "        )\n",
    "        assert (\n",
    "            sim.get_articulated_object_motion_type(robot_id)\n",
    "            == habitat_sim.physics.MotionType.DYNAMIC\n",
    "        )\n",
    "\n",
    "        if make_video:\n",
    "            vut.make_video(\n",
    "                observations,\n",
    "                \"rgba_camera_1stperson\",\n",
    "                \"color\",\n",
    "                output_path + \"URDF_basics\",\n",
    "                open_vid=show_video,\n",
    "            )\n",
    "\n",
    "        # clear all robots\n",
    "        for robot_id in sim.get_existing_articulated_object_ids():\n",
    "            sim.remove_articulated_object(robot_id)\n",
    "        # [/basics]\n",
    "\n",
    "        # [joint motors]\n",
    "        observations = []\n",
    "\n",
    "        # load a URDF file with a fixed base\n",
    "        robot_file = urdf_files[\"iiwa\"]\n",
    "        robot_id = sim.add_articulated_object_from_urdf(robot_file, True)\n",
    "\n",
    "        # place the robot root state relative to the agent\n",
    "        place_robot_from_agent(sim, robot_id, -3.14)\n",
    "\n",
    "        # query any damping motors created by default\n",
    "        existing_joint_motors = sim.get_existing_joint_motors(robot_id)\n",
    "        print(\"default damping motors (motor_id -> dof): \" + str(existing_joint_motors))\n",
    "\n",
    "        # get the max_impulse of the damping motors\n",
    "        for motor_id in existing_joint_motors:\n",
    "            motor_settings = sim.get_joint_motor_settings(robot_id, motor_id)\n",
    "            print(\n",
    "                \"   motor(\"\n",
    "                + str(motor_id)\n",
    "                + \"): max_impulse = \"\n",
    "                + str(motor_settings.max_impulse)\n",
    "            )\n",
    "\n",
    "        # simulate\n",
    "        observations += simulate(sim, dt=1.5, get_frames=make_video)\n",
    "\n",
    "        # create a new velocity motor\n",
    "        joint_motor_settings = habitat_sim.physics.JointMotorSettings(\n",
    "            0,  # position_target\n",
    "            0,  # position_gain\n",
    "            1.0,  # velocity_target\n",
    "            1.0,  # velocity_gain\n",
    "            10.0,  # max_impulse\n",
    "        )\n",
    "        new_motor_id = sim.create_joint_motor(\n",
    "            robot_id, 1, joint_motor_settings  # robot object id  # dof  # settings\n",
    "        )\n",
    "        existing_joint_motors = sim.get_existing_joint_motors(robot_id)\n",
    "        print(\"new_motor_id: \" + str(new_motor_id))\n",
    "        print(\n",
    "            \"existing motors after create (motor_id -> dof): \"\n",
    "            + str(existing_joint_motors)\n",
    "        )\n",
    "\n",
    "        # simulate\n",
    "        observations += simulate(sim, dt=1.5, get_frames=make_video)\n",
    "\n",
    "        # reverse the motor velocity\n",
    "        joint_motor_settings.velocity_target = -1.0\n",
    "        sim.update_joint_motor(robot_id, new_motor_id, joint_motor_settings)\n",
    "\n",
    "        # simulate\n",
    "        observations += simulate(sim, dt=1.5, get_frames=make_video)\n",
    "\n",
    "        # remove the new joint motor\n",
    "        sim.remove_joint_motor(robot_id, new_motor_id)\n",
    "\n",
    "        # create joint motors for all valid dofs to control a pose (1.1 for all dofs)\n",
    "        joint_motor_settings = habitat_sim.physics.JointMotorSettings(\n",
    "            0.5, 1.0, 0, 0, 1.0\n",
    "        )\n",
    "        dofs_to_motor_ids = sim.create_motors_for_all_dofs(\n",
    "            robot_id,\n",
    "            joint_motor_settings,  # (optional) motor settings, if not provided will be default (no gains)\n",
    "        )\n",
    "        print(\"New motors (motor_ids -> dofs): \" + str(dofs_to_motor_ids))\n",
    "\n",
    "        # simulate\n",
    "        observations += simulate(sim, dt=1.5, get_frames=make_video)\n",
    "\n",
    "        # remove all motors\n",
    "        existing_joint_motors = sim.get_existing_joint_motors(robot_id)\n",
    "        print(\n",
    "            \"All motors (motor_id -> dof) before removal: \" + str(existing_joint_motors)\n",
    "        )\n",
    "        for motor_id in existing_joint_motors:\n",
    "            sim.remove_joint_motor(robot_id, motor_id)\n",
    "        print(\n",
    "            \"All motors (motor_id -> dof) before removal: \"\n",
    "            + str(sim.get_existing_joint_motors(robot_id))\n",
    "        )\n",
    "\n",
    "        # simulate\n",
    "        observations += simulate(sim, dt=1.5, get_frames=make_video)\n",
    "\n",
    "        if make_video:\n",
    "            vut.make_video(\n",
    "                observations,\n",
    "                \"rgba_camera_1stperson\",\n",
    "                \"color\",\n",
    "                output_path + \"URDF_joint_motors\",\n",
    "                open_vid=show_video,\n",
    "            )\n",
    "        # [/joint motors]\n",
    "\n",
    "        remove_all_objects(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--no-display\", dest=\"display\", action=\"store_false\")\n",
    "    parser.add_argument(\"--no-make-video\", dest=\"make_video\", action=\"store_false\")\n",
    "    parser.set_defaults(show_video=True, make_video=True)\n",
    "    args, _ = parser.parse_known_args()\n",
    "    show_video = args.display\n",
    "    display = args.display\n",
    "    make_video = args.make_video\n",
    "\n",
    "    if make_video and not os.path.exists(output_path):\n",
    "        os.mkdir(output_path)\n",
    "\n",
    "    main(make_video, show_video)\n",
    "    test_constraints(make_video, show_video)\n",
    "    # test_urdf_memory()\n",
    "    # demo_contact_profile()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "nb_python//py:percent,colabs//ipynb",
   "main_language": "python",
   "notebook_metadata_filter": "all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
